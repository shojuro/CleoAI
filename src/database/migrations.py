"""
Database migration utilities for CleoAI.

This module provides:
- Migration management commands
- Backup and restore functionality
- Schema versioning
- Data migration helpers
"""
import os
import logging
import subprocess
from datetime import datetime
from typing import Optional, List, Dict, Any
from pathlib import Path

from alembic import command
from alembic.config import Config
from alembic.script import ScriptDirectory
from alembic.runtime.migration import MigrationContext
from sqlalchemy import create_engine, text

from .connection import get_database_url, init_database
from ..monitoring import capture_exception, audit_logger

logger = logging.getLogger(__name__)


class MigrationManager:
    """Manage database migrations."""
    
    def __init__(self, alembic_ini_path: str = "alembic.ini"):
        """
        Initialize migration manager.
        
        Args:
            alembic_ini_path: Path to alembic.ini file
        """
        self.alembic_cfg = Config(alembic_ini_path)
        self.alembic_cfg.set_main_option("sqlalchemy.url", get_database_url())
        
    def create_migration(self, message: str, autogenerate: bool = True) -> str:
        """
        Create a new migration.
        
        Args:
            message: Migration message
            autogenerate: Whether to autogenerate based on model changes
            
        Returns:
            Path to created migration file
        """
        try:
            # Create revision
            if autogenerate:
                revision = command.revision(
                    self.alembic_cfg,
                    message=message,
                    autogenerate=True
                )
                logger.info(f"Created autogenerated migration: {message}")
            else:
                revision = command.revision(
                    self.alembic_cfg,
                    message=message
                )
                logger.info(f"Created empty migration: {message}")
            
            # Log audit event
            audit_logger.log_event(
                event_type="migration_created",
                resource_type="database",
                action="create",
                metadata={"message": message, "autogenerate": autogenerate}
            )
            
            return revision
            
        except Exception as e:
            logger.error(f"Failed to create migration: {e}")
            capture_exception(e, context={"migration_message": message})
            raise
    
    def run_migrations(self, target: str = "head") -> None:
        """
        Run migrations up to target revision.
        
        Args:
            target: Target revision (default: head)
        """
        try:
            logger.info(f"Running migrations to {target}")
            
            # Run upgrade
            command.upgrade(self.alembic_cfg, target)
            
            # Log audit event
            audit_logger.log_event(
                event_type="migration_applied",
                resource_type="database",
                action="update",
                metadata={"target": target}
            )
            
            logger.info("Migrations completed successfully")
            
        except Exception as e:
            logger.error(f"Failed to run migrations: {e}")
            capture_exception(e, context={"target": target})
            raise
    
    def rollback_migration(self, target: str = "-1") -> None:
        """
        Rollback migrations to target revision.
        
        Args:
            target: Target revision (default: -1 for previous)
        """
        try:
            logger.warning(f"Rolling back migrations to {target}")
            
            # Run downgrade
            command.downgrade(self.alembic_cfg, target)
            
            # Log audit event
            audit_logger.log_event(
                event_type="migration_rollback",
                resource_type="database",
                action="update",
                metadata={"target": target}
            )
            
            logger.info("Rollback completed successfully")
            
        except Exception as e:
            logger.error(f"Failed to rollback migrations: {e}")
            capture_exception(e, context={"target": target})
            raise
    
    def get_current_revision(self) -> Optional[str]:
        """
        Get current database revision.
        
        Returns:
            Current revision ID or None
        """
        try:
            engine = init_database()
            
            with engine.connect() as connection:
                context = MigrationContext.configure(connection)
                return context.get_current_revision()
                
        except Exception as e:
            logger.error(f"Failed to get current revision: {e}")
            return None
    
    def get_pending_migrations(self) -> List[str]:
        """
        Get list of pending migrations.
        
        Returns:
            List of pending migration IDs
        """
        try:
            # Get script directory
            script_dir = ScriptDirectory.from_config(self.alembic_cfg)
            
            # Get current revision
            current = self.get_current_revision()
            
            # Get pending revisions
            pending = []
            for revision in script_dir.walk_revisions():
                if current is None or revision.revision != current:
                    pending.append(revision.revision)
                else:
                    break
            
            return list(reversed(pending))
            
        except Exception as e:
            logger.error(f"Failed to get pending migrations: {e}")
            return []
    
    def show_history(self) -> None:
        """Show migration history."""
        try:
            command.history(self.alembic_cfg)
        except Exception as e:
            logger.error(f"Failed to show history: {e}")
    
    def validate_migrations(self) -> bool:
        """
        Validate that migrations are in sync with models.
        
        Returns:
            True if in sync, False otherwise
        """
        try:
            # Check for model changes
            command.check(self.alembic_cfg)
            logger.info("Database schema is in sync with models")
            return True
            
        except Exception:
            logger.warning("Database schema differs from models")
            return False


class DatabaseBackup:
    """Handle database backups and restoration."""
    
    def __init__(self, backup_dir: str = "backups"):
        """
        Initialize backup manager.
        
        Args:
            backup_dir: Directory for storing backups
        """
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(exist_ok=True)
        
    def create_backup(
        self,
        name: Optional[str] = None,
        compress: bool = True
    ) -> Path:
        """
        Create database backup.
        
        Args:
            name: Backup name (default: timestamp)
            compress: Whether to compress backup
            
        Returns:
            Path to backup file
        """
        try:
            # Generate backup filename
            if name is None:
                name = f"cleoai_backup_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}"
            
            backup_file = self.backup_dir / f"{name}.sql"
            if compress:
                backup_file = backup_file.with_suffix('.sql.gz')
            
            # Get database config
            from .connection import DatabaseConfig
            config = DatabaseConfig()
            
            # Build pg_dump command
            cmd = [
                "pg_dump",
                "-h", config.host,
                "-p", str(config.port),
                "-U", config.user,
                "-d", config.database,
                "--clean",
                "--if-exists",
                "--no-owner",
                "--no-privileges"
            ]
            
            # Set password via environment
            env = os.environ.copy()
            env["PGPASSWORD"] = config.password
            
            # Run backup
            logger.info(f"Creating backup: {backup_file}")
            
            if compress:
                # Pipe through gzip
                with open(backup_file, 'wb') as f:
                    dump_proc = subprocess.Popen(
                        cmd,
                        env=env,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE
                    )
                    gzip_proc = subprocess.Popen(
                        ["gzip", "-9"],
                        stdin=dump_proc.stdout,
                        stdout=f,
                        stderr=subprocess.PIPE
                    )
                    dump_proc.stdout.close()
                    gzip_out, gzip_err = gzip_proc.communicate()
                    
                    if gzip_proc.returncode != 0:
                        raise Exception(f"Backup compression failed: {gzip_err.decode()}")
            else:
                # Direct dump
                with open(backup_file, 'w') as f:
                    result = subprocess.run(
                        cmd,
                        env=env,
                        stdout=f,
                        stderr=subprocess.PIPE,
                        check=True
                    )
            
            # Log audit event
            audit_logger.log_event(
                event_type="backup_created",
                resource_type="database",
                action="create",
                metadata={
                    "backup_file": str(backup_file),
                    "compressed": compress
                }
            )
            
            logger.info(f"Backup created successfully: {backup_file}")
            return backup_file
            
        except Exception as e:
            logger.error(f"Failed to create backup: {e}")
            capture_exception(e, context={"backup_name": name})
            raise
    
    def restore_backup(self, backup_file: Path) -> None:
        """
        Restore database from backup.
        
        Args:
            backup_file: Path to backup file
        """
        try:
            if not backup_file.exists():
                raise FileNotFoundError(f"Backup file not found: {backup_file}")
            
            # Get database config
            from .connection import DatabaseConfig
            config = DatabaseConfig()
            
            # Build psql command
            cmd = [
                "psql",
                "-h", config.host,
                "-p", str(config.port),
                "-U", config.user,
                "-d", config.database
            ]
            
            # Set password via environment
            env = os.environ.copy()
            env["PGPASSWORD"] = config.password
            
            logger.warning(f"Restoring database from: {backup_file}")
            
            if backup_file.suffix == '.gz':
                # Decompress and restore
                gunzip_proc = subprocess.Popen(
                    ["gunzip", "-c", str(backup_file)],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE
                )
                psql_proc = subprocess.Popen(
                    cmd,
                    env=env,
                    stdin=gunzip_proc.stdout,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE
                )
                gunzip_proc.stdout.close()
                psql_out, psql_err = psql_proc.communicate()
                
                if psql_proc.returncode != 0:
                    raise Exception(f"Restore failed: {psql_err.decode()}")
            else:
                # Direct restore
                with open(backup_file, 'r') as f:
                    result = subprocess.run(
                        cmd,
                        env=env,
                        stdin=f,
                        stderr=subprocess.PIPE,
                        check=True
                    )
            
            # Log audit event
            audit_logger.log_event(
                event_type="backup_restored",
                resource_type="database",
                action="update",
                metadata={"backup_file": str(backup_file)}
            )
            
            logger.info("Database restored successfully")
            
        except Exception as e:
            logger.error(f"Failed to restore backup: {e}")
            capture_exception(e, context={"backup_file": str(backup_file)})
            raise
    
    def list_backups(self) -> List[Dict[str, Any]]:
        """
        List available backups.
        
        Returns:
            List of backup information
        """
        backups = []
        
        for backup_file in self.backup_dir.glob("*.sql*"):
            stat = backup_file.stat()
            backups.append({
                "name": backup_file.name,
                "path": str(backup_file),
                "size": stat.st_size,
                "created": datetime.fromtimestamp(stat.st_ctime),
                "compressed": backup_file.suffix == '.gz'
            })
        
        return sorted(backups, key=lambda x: x['created'], reverse=True)
    
    def cleanup_old_backups(self, keep_days: int = 30) -> int:
        """
        Remove backups older than specified days.
        
        Args:
            keep_days: Number of days to keep backups
            
        Returns:
            Number of backups removed
        """
        cutoff = datetime.utcnow().timestamp() - (keep_days * 86400)
        removed = 0
        
        for backup_file in self.backup_dir.glob("*.sql*"):
            if backup_file.stat().st_ctime < cutoff:
                backup_file.unlink()
                removed += 1
                logger.info(f"Removed old backup: {backup_file.name}")
        
        if removed > 0:
            audit_logger.log_event(
                event_type="backup_cleanup",
                resource_type="database",
                action="delete",
                metadata={"removed_count": removed, "keep_days": keep_days}
            )
        
        return removed


# Global instances
migration_manager = MigrationManager()
backup_manager = DatabaseBackup()